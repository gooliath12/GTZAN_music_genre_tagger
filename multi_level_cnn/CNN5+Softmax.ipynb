{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Convolutional Layers + 2 Fully-connected Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, the entire neural network, including 5 conv layers and 2 fully-connected layers are defined using keras.\n",
    "\n",
    "Before running this script, **you should first run \"`Convert GTZAN to npy.ipynb`\" to make data ready.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Input, Dense, merge, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from keras.utils.visualize_util import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "input_length = 12000 * 29 # length of \"vectorized\" music clip\n",
    "PATH_WEIGHTS = './weights/weights_layer4_theano.hdf5' # Path to pre-trained weights\n",
    "PATH_X = './dataset/X.npy'\n",
    "PATH_Y = './dataset/Y.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "X, Y_pre = np.load(PATH_X), np.load(PATH_Y)\n",
    "\n",
    "# Encode Y_pre to one-hot(Y)\n",
    "Y = np.zeros((1000, 10))\n",
    "Y[np.arange(1000), Y_pre] = 1\n",
    "\n",
    "# Split Dataset (90% train + 10% test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = Input(shape=(1, input_length))\n",
    "melgram = Melspectrogram(n_dft=512, n_hop=256, power_melgram=2.0,\n",
    "                                # input_shape=(1, input_length),\n",
    "                                     trainable_kernel=False,\n",
    "                                     trainable_fb=False,\n",
    "                                     return_decibel_melgram=True,\n",
    "                                     sr=12000, n_mels=96,\n",
    "                                     fmin=0.0, fmax=6000,\n",
    "                                     name='melgram')(x)\n",
    "\n",
    "# 1st conv layer\n",
    "conv1 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(melgram)\n",
    "conv1 = BatchNormalization(axis=1, mode=2, trainable=False)(conv1)\n",
    "conv1 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv1)\n",
    "conv1 = MaxPooling2D(pool_size=(2, 4))(conv1)\n",
    "avg1 = GlobalAveragePooling2D()(conv1)\n",
    "\n",
    "# 2nd conv layer\n",
    "conv2 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv1)\n",
    "conv2 = BatchNormalization(axis=1, mode=2, trainable=False)(conv2)\n",
    "conv2 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv2)\n",
    "conv2 = MaxPooling2D(pool_size=(3, 4))(conv2)\n",
    "avg2 = GlobalAveragePooling2D()(conv2)\n",
    "\n",
    "# 3rd conv layer\n",
    "conv3 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv2)\n",
    "conv3 = BatchNormalization(axis=1, mode=2, trainable=False)(conv3)\n",
    "conv3 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv3)\n",
    "conv3 = MaxPooling2D(pool_size=(2, 5))(conv3)\n",
    "avg3 = GlobalAveragePooling2D()(conv3)\n",
    "\n",
    "# 4th conv layer\n",
    "conv4 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv3)\n",
    "conv4 = BatchNormalization(axis=1, mode=2, trainable=False)(conv4)\n",
    "conv4 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv4)\n",
    "conv4 = MaxPooling2D(pool_size=(2, 4))(conv4)\n",
    "avg4 = GlobalAveragePooling2D()(conv4)\n",
    "\n",
    "# 5th conv layer\n",
    "conv5 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv4)\n",
    "conv5 = BatchNormalization(axis=1, mode=2, trainable=False)(conv5)\n",
    "conv5 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv5)\n",
    "conv5 = MaxPooling2D(pool_size=(4, 4))(conv5)\n",
    "avg5 = GlobalAveragePooling2D()(conv5)\n",
    "\n",
    "# Concatenate 5 intermediate outputs\n",
    "concatenated = merge([avg1, avg2, avg3, avg4, avg5], mode='concat', concat_axis=1)\n",
    "\n",
    "# Fully-connected & dropout layers\n",
    "dense1 = Dense(32, input_shape=[160], activation='relu')(concatenated)\n",
    "dr1 = Dropout(0.2)(dense1)\n",
    "out = Dense(10, input_shape=[32], activation='softmax')(dr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Model(input=x, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1, 348000)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "melgram (Melspectrogram)         (None, 1, 96, 1360)   287840      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 96, 1360)  320         melgram[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 32, 96, 1360)  128         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 32, 96, 1360)  0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 48, 340)   0           elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 48, 340)   9248        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 32, 48, 340)   128         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 32, 48, 340)   0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 16, 85)    0           elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 32, 16, 85)    9248        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 32, 16, 85)    128         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 32, 16, 85)    0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 8, 17)     0           elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 8, 17)     9248        maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 32, 8, 17)     128         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 32, 8, 17)     0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 32, 4, 4)      0           elu_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 32, 4, 4)      9248        maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 32, 4, 4)      128         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 32, 4, 4)      0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 32, 1, 1)      0           elu_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_1 (Global (None, 32)            0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_2 (Global (None, 32)            0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_3 (Global (None, 32)            0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_4 (Global (None, 32)            0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_5 (Global (None, 32)            0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 160)           0           globalaveragepooling2d_1[0][0]   \n",
      "                                                                   globalaveragepooling2d_2[0][0]   \n",
      "                                                                   globalaveragepooling2d_3[0][0]   \n",
      "                                                                   globalaveragepooling2d_4[0][0]   \n",
      "                                                                   globalaveragepooling2d_5[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            5152        merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 32)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            330         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 331,274\n",
      "Trainable params: 5,482\n",
      "Non-trainable params: 325,792\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show summaries of the model\n",
    "model.summary()\n",
    "\n",
    "# Show plot of the structure\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "model.load_weights(PATH_WEIGHTS, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model_his = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model_eval = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
