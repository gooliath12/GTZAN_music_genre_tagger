{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Convolutional Layers + 2 Fully-connected Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, the entire neural network, including 5 conv layers and 2 fully-connected layers are defined using keras.\n",
    "\n",
    "Before running this script, **you should first run \"`Convert GTZAN to npy.ipynb`\" to make data ready.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Input, Dense, merge, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from keras.utils.visualize_util import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "input_length = 12000 * 29\n",
    "PATH_WEIGHTS = './weights/weights_layer4_theano.hdf5'\n",
    "PATH_X = './dataset/X.npy'\n",
    "PATH_Y = './dataset/Y.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "X, Y_pre = np.load(PATH_X), np.load(PATH_Y)\n",
    "\n",
    "# Encode Y_pre to one-hot(Y)\n",
    "Y = np.zeros((1000, 10))\n",
    "Y[np.arange(1000), Y_pre] = 1\n",
    "\n",
    "# Split Dataset (90% train + 10% test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = Input(shape=(1, input_length))\n",
    "melgram = Melspectrogram(n_dft=512, n_hop=256, power_melgram=2.0,\n",
    "                                # input_shape=(1, input_length),\n",
    "                                     trainable_kernel=False,\n",
    "                                     trainable_fb=False,\n",
    "                                     return_decibel_melgram=True,\n",
    "                                     sr=12000, n_mels=96,\n",
    "                                     fmin=0.0, fmax=6000,\n",
    "                                     name='melgram')(x)\n",
    "\n",
    "# 1st conv layer\n",
    "conv1 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(melgram)\n",
    "conv1 = BatchNormalization(axis=1, mode=2, trainable=False)(conv1)\n",
    "conv1 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv1)\n",
    "conv1 = MaxPooling2D(pool_size=(2, 4))(conv1)\n",
    "avg1 = GlobalAveragePooling2D()(conv1)\n",
    "\n",
    "# 2nd conv layer\n",
    "conv2 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv1)\n",
    "conv2 = BatchNormalization(axis=1, mode=2, trainable=False)(conv2)\n",
    "conv2 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv2)\n",
    "conv2 = MaxPooling2D(pool_size=(3, 4))(conv2)\n",
    "avg2 = GlobalAveragePooling2D()(conv2)\n",
    "\n",
    "# 3rd conv layer\n",
    "conv3 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv2)\n",
    "conv3 = BatchNormalization(axis=1, mode=2, trainable=False)(conv3)\n",
    "conv3 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv3)\n",
    "conv3 = MaxPooling2D(pool_size=(2, 5))(conv3)\n",
    "avg3 = GlobalAveragePooling2D()(conv3)\n",
    "\n",
    "# 4th conv layer\n",
    "conv4 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv3)\n",
    "conv4 = BatchNormalization(axis=1, mode=2, trainable=False)(conv4)\n",
    "conv4 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv4)\n",
    "conv4 = MaxPooling2D(pool_size=(2, 4))(conv4)\n",
    "avg4 = GlobalAveragePooling2D()(conv4)\n",
    "\n",
    "# 5th conv layer\n",
    "conv5 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', trainable=False)(conv4)\n",
    "conv5 = BatchNormalization(axis=1, mode=2, trainable=False)(conv5)\n",
    "conv5 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv5)\n",
    "conv5 = MaxPooling2D(pool_size=(4, 4))(conv5)\n",
    "avg5 = GlobalAveragePooling2D()(conv5)\n",
    "\n",
    "# Concatenate 5 intermediate outputs\n",
    "concatenated = merge([avg1, avg2, avg3, avg4, avg5], mode='concat', concat_axis=1)\n",
    "\n",
    "# Fully-connected & dropout layers\n",
    "dense1 = Dense(32, input_shape=[160], activation='relu')(concatenated)\n",
    "dr1 = Dropout(0.2)(dense1)\n",
    "out = Dense(10, input_shape=[32], activation='softmax')(dr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = Model(input=x, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summaries of the model\n",
    "model.summary()\n",
    "\n",
    "# Show plot of the structure\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "model.load_weights(PATH_WEIGHTS, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model_his = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model_eval = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
