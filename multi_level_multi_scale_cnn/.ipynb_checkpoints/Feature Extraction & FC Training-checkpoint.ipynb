{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Fully-connected Layers Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in this notebook is used for feature extraction using CNNs trained in `Train Local Feature Extractors.ipynb` and the training of classifier based on extracted features. See each section below for detailed instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Comment out the line below if not using GPU\n",
    "os.environ['THEANO_FLAGS'] = \"floatX=float32,device=cuda,exception_verbosity=high\"\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, merge, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.visualize_util import plot\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below provide a templete for defining a CNN model used as local feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_cnn(seg_length, pool_sizes_hori):\n",
    "    '''\n",
    "    The function for building CNNs.\n",
    "    Each CNN model handles one segment of mel-spectrograms at a time.\n",
    "    The size of mel-spectrogram sgements is defined by \"seg_length\"\n",
    "    \"seg_length\" and pooling layer sizes are set adjusting to different scales.\n",
    "    '''\n",
    "    psh = [0] + pool_sizes_hori # padding at front for index alignment\n",
    "    \n",
    "    # input\n",
    "    x = Input(shape=(1, 96, seg_length))\n",
    "\n",
    "    # 1st conv layer\n",
    "    conv1 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', name='conv1_{}'.format(seg_length), trainable=False)(x)\n",
    "    conv1 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv1)\n",
    "    conv1 = MaxPooling2D(pool_size=(2, psh[1]))(conv1)\n",
    "    avg1 = GlobalAveragePooling2D()(conv1)\n",
    "\n",
    "    # 2nd conv layer\n",
    "    conv2 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', name='conv2_{}'.format(seg_length), trainable=False)(conv1)\n",
    "    conv2 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(3, psh[2]))(conv2)\n",
    "    avg2 = GlobalAveragePooling2D()(conv2)\n",
    "\n",
    "    # 3rd conv layer\n",
    "    conv3 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', name='conv3_{}'.format(seg_length), trainable=False)(conv2)\n",
    "    conv3 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv3)\n",
    "    conv3 = MaxPooling2D(pool_size=(2, psh[3]))(conv3)\n",
    "    avg3 = GlobalAveragePooling2D()(conv3)\n",
    "\n",
    "    # 4th conv layer\n",
    "    conv4 = Convolution2D(32, 3, 3, border_mode='same', init='he_normal', name='conv4_{}'.format(seg_length), trainable=False)(conv3)\n",
    "    conv4 = keras.layers.advanced_activations.ELU(alpha=1.0)(conv4)\n",
    "    conv4 = MaxPooling2D(pool_size=(2, psh[4]))(conv4)\n",
    "    avg4 = GlobalAveragePooling2D()(conv4)\n",
    "\n",
    "    # Concatenate 5 intermediate outputs\n",
    "    concatenated = merge([avg1, avg2, avg3, avg4], mode='concat', concat_axis=1)\n",
    "    \n",
    "    # define model\n",
    "    model = Model(input=x, output=concatenated)\n",
    "    \n",
    "    # load pre-trained weights\n",
    "    model.load_weights(PATH_WEIGHTS, by_name=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load \"raw\" dataset (spectrograms whose features to be extracted).\n",
    "- `X_train`: Training data\n",
    "- `Y_train`: Labels of training data\n",
    "- `X_test`: Heldout test data\n",
    "- `Y_test`: Labels of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train Dataset (X_train, Y_train)\n",
    "X_train = np.load('./dataset/X_train.npy')\n",
    "Y_train_pre = np.load('./dataset/Y_train.npy').astype(int)\n",
    "\n",
    "Y_train = np.zeros((Y_train_pre.shape[0], 10))\n",
    "Y_train[np.arange(Y_train_pre.shape[0]), Y_train_pre] = 1\n",
    "\n",
    "# Load Test Dataset (X_test, Y_test)\n",
    "X_test = np.load('./dataset/X_test.npy')\n",
    "Y_test_pre = np.load('./dataset/Y_test.npy').astype(int)\n",
    "\n",
    "Y_test = np.zeros((Y_test_pre.shape[0], 10))\n",
    "Y_test[np.arange(Y_test_pre.shape[0]), Y_test_pre] = 1\n",
    "\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in this section are used for extracting features from all song clips in GTZAN using local feature extractors (4 CNN models) pre-trained in `Train Local Feature Extractors.ipynb`. Since the extraction process is quite slow, after extraction is done, features will be stored under the specific path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(X, seg_lengths, pool_sizes_horis, flag_save=True, tr_te='tr'):\n",
    "    '''\n",
    "    Extract features in different scales for all mel-spectrograms.\n",
    "    Inputs:\n",
    "        - X: spectrograms to be processed\n",
    "        - seg_lengths, pool_sizes_horis: parameters to build CNN models\n",
    "        - flag_save: Set True to save extracted feature vactors\n",
    "    Return:\n",
    "        extracted features from all images in X\n",
    "    '''\n",
    "    # Build cnn model and load pre-trained weights\n",
    "    models = []\n",
    "    for i, seg_length in enumerate(seg_lengths):\n",
    "        pool_sizes_hori = pool_sizes_horis[i] # select pool layer sizes\n",
    "        cnn = gen_cnn(seg_length, pool_sizes_hori) # generate model\n",
    "        PATH_WEIGHTS = './weights/local_cnn_{}.h5'.format(seg_length)\n",
    "        cnn.load_weights(PATH_WEIGHTS, by_name=True) # load pre-trained weights\n",
    "        models.append((cnn, seg_length))\n",
    "    \n",
    "    num_pics, length = X.shape[0], X.shape[3]\n",
    "    num_models = len(models) # Number of CNNs\n",
    "    new_X = np.zeros((num_pics, 128*num_models))\n",
    "    for i, params in enumerate(models):\n",
    "        cnn, seg_length = params # read model and corresponding seg_length\n",
    "        features = np.zeros((num_pics, 128))\n",
    "        for j in xrange(length/seg_length):\n",
    "            feature = cnn.predict(X[:, :, :, j*seg_length:(j+1)*seg_length]) # extract feature using cnn\n",
    "            features += feature\n",
    "        features /= length/seg_length # compute mean on feature vectors among all segments\n",
    "        assert features.shape == (num_pics, 128)\n",
    "        new_X[:, i*128:(i+1)*128] = features \n",
    "        \n",
    "    if flag_save:\n",
    "        if not os.path.exists('./local_features/'):\n",
    "            os.mkdir('./local_features/')\n",
    "        if tr_te == 'tr':\n",
    "            np.save('./local_features/X_train_extracted.npy', new_X)\n",
    "        else:\n",
    "            np.save('./local_features/X_test_extracted.npy', new_X)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "seg_lengths = [30, 60, 120, 240]\n",
    "pool_sizes_horis = [[2, 2, 2, 2], [3, 2, 2, 2], [3, 3, 2, 2], [4, 4, 3, 2]] # sizes of pooling layers (in horizontal direction)\n",
    "\n",
    "# Call function to extract feature from each song clip\n",
    "X_train_ext = extract_feature(X_train, seg_lengths, pool_sizes_horis)\n",
    "X_test_ext = extract_feature(X_test, seg_lengths, pool_sizes_horis, tr_te='te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Or load the features if extraction has been done before\n",
    "X_train_ext = np.load('./local_features/X_train_extracted.npy') # \"ext\": extracted feature\n",
    "X_test_ext = np.load('./local_features/X_test_extracted.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge train & test data together for cross-validation\n",
    "X_ext = np.concatenate((X_train_ext, X_test_ext), axis=0)\n",
    "Y_ext = np.concatenate((Y_train, Y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a neural-network based classifier and train it on features extracted in `Feature Extraction` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_classifier(lambd=0.2):\n",
    "    '''\n",
    "    Generate a classifier model with 2 hidden dense layers\n",
    "    and dropout regularization.\n",
    "    '''\n",
    "    # Model input\n",
    "    x = Input(shape=(512,))\n",
    "    \n",
    "    # First hidden layer\n",
    "    dense1 = Dense(256, input_shape=[512], activation='relu')(x)\n",
    "    dr1 = Dropout(lambd)(dense1)\n",
    "    \n",
    "    # Model output\n",
    "    out = Dense(10, input_shape=[128], activation='softmax')(dr1)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(input=x, output=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile and Train Model\n",
    "classifier = gen_classifier()\n",
    "# classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_his = classifier.fit(X_train_ext, Y_train, validation_data=(X_test_ext, Y_test), nb_epoch=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Training History (for plotting)\n",
    "import pickle, datetime\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "with open('./train_logs/train_his_{}_{}'.format('FC', now), 'wb') as file_pi:\n",
    "    pickle.dump(model_his.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and Plot Accuracy per Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar implementation can be seen in \"Multi-level CNN\" part. \n",
    "\n",
    "Run all cells to get accuracy per genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "names = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "total = [0.0] * 10\n",
    "correct = [0.0] * 10\n",
    "\n",
    "def acc_per_genre(model_gen, X, Y, epoches=500):\n",
    "    seed = 6\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        # print 'One fold'\n",
    "        model = model_gen()\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        # Fit the model\n",
    "        model.fit(X[train], Y[train], nb_epoch=epoches, verbose=0)\n",
    "        # make predictions on test data\n",
    "        Y_pred = model.predict(X[test])\n",
    "        Y_pred, Y_gold = np.argmax(Y_pred, axis=1), np.argmax(Y[test], axis=1)\n",
    "        assert Y_pred.shape[0] == Y[test].shape[0]  \n",
    "        for i in xrange(Y_gold.shape[0]):\n",
    "            total[Y_gold[i]] += 1\n",
    "            if Y_gold[i] == Y_pred[i]:\n",
    "                correct[Y_gold[i]] += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function defined above to compute accuracies\n",
    "acc_per_genre(gen_classifier, X_ext, Y_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot function\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_genre_acc(names, percentage):\n",
    "    N = len(names)\n",
    "    \n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.5     # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind, percentage, width) #, yerr=men_std)\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Accuracy by genre')\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(names, rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt_genre_acc(names, percentage)\n",
    "fig.savefig('./acc_by_genre_p2.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
